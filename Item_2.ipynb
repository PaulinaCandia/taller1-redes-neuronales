{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzttsJ2vUMkB"
      },
      "outputs": [],
      "source": [
        "#base\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / y_true.size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementación de la capa densa (FCLayer)\n",
        "\n",
        "class FCLayer:\n",
        "    def __init__(self, input_size, output_size, lambda_reg=0.0):\n",
        "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
        "        self.bias = np.random.rand(1, output_size) - 0.5\n",
        "        self.lambda_reg = lambda_reg\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = np.dot(self.input, self.weights) + self.bias\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        input_gradient = np.dot(output_gradient, self.weights.T)\n",
        "        weights_gradient = np.dot(self.input.T, output_gradient)\n",
        "        weights_gradient += self.lambda_reg * self.weights\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.bias -= learning_rate * np.mean(output_gradient, axis=0)\n",
        "        return input_gradient\n",
        "\n"
      ],
      "metadata": {
        "id": "BNheYvTiUUi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementación de la capa de activación\n",
        "class ActivationLayer:\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = self.activation(self.input)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        return output_gradient * self.activation_prime(self.input)\n",
        "\n"
      ],
      "metadata": {
        "id": "4hyq27aMUWzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementación de la capa de pooling\n",
        "class PoolingLayer:\n",
        "    def __init__(self, pool_size, mode='max'):\n",
        "        self.pool_size = pool_size\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.output = np.zeros((input.shape[0], input.shape[1] // self.pool_size))\n",
        "        for i in range(0, input.shape[1], self.pool_size):\n",
        "            if self.mode == 'max':\n",
        "                self.output[:, i // self.pool_size] = np.max(input[:, i:i + self.pool_size], axis=1)\n",
        "            elif self.mode == 'average':\n",
        "                self.output[:, i // self.pool_size] = np.mean(input[:, i:i + self.pool_size], axis=1)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        input_gradient = np.zeros_like(self.input)\n",
        "        for i in range(0, self.input.shape[1], self.pool_size):\n",
        "            if self.mode == 'max':\n",
        "                max_indices = np.argmax(self.input[:, i:i + self.pool_size], axis=1)\n",
        "                input_gradient[:, i:i + self.pool_size] = (np.arange(self.pool_size) == max_indices[:, None]) * output_gradient[:, i // self.pool_size][:, None]\n",
        "            elif self.mode == 'average':\n",
        "                input_gradient[:, i:i + self.pool_size] = output_gradient[:, i // self.pool_size][:, None] / self.pool_size\n",
        "        return input_gradient\n",
        "\n"
      ],
      "metadata": {
        "id": "gRmMkbtmUZDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementación de la red neuronal\n",
        "class Network:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.loss_prime = None\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def use(self, loss, loss_prime):\n",
        "        self.loss = loss\n",
        "        self.loss_prime = loss_prime\n",
        "\n",
        "    def predict(self, input_data):\n",
        "        samples = len(input_data)\n",
        "        result = []\n",
        "        for i in range(samples):\n",
        "            output = input_data[i]\n",
        "            for layer in self.layers:\n",
        "                output = layer.forward(output)\n",
        "            result.append(output)\n",
        "        return result\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs, learning_rate):\n",
        "        samples = len(X_train)\n",
        "        for epoch in range(epochs):\n",
        "            print(f'Epoch {epoch+1}/{epochs}')\n",
        "            for i in range(samples):\n",
        "                output = X_train[i]\n",
        "                for layer in self.layers:\n",
        "                    output = layer.forward(output)\n",
        "                loss = self.loss(y_train[i], output)\n",
        "                output_gradient = self.loss_prime(y_train[i], output)\n",
        "                for layer in reversed(self.layers):\n",
        "                    output_gradient = layer.backward(output_gradient, learning_rate)\n",
        "            print(f'Loss: {loss}')\n",
        "\n"
      ],
      "metadata": {
        "id": "8gTjm2RQUbPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargado de datos\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "y_one_hot = np.zeros((y.size, 10))\n",
        "y_one_hot[np.arange(y.size), y] = 1\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.3, random_state=42)\n",
        "\n",
        "#creacion de la red\n",
        "entrada_dim = X_train.shape[1]\n",
        "model = Network()\n",
        "lambda_reg = 0.001\n",
        "model.add(FCLayer(entrada_dim, 256, lambda_reg=lambda_reg))\n",
        "model.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "model.add(PoolingLayer(pool_size=2, mode='max'))\n",
        "model.add(FCLayer(128, 256, lambda_reg=lambda_reg))\n",
        "model.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "model.add(FCLayer(256, 10, lambda_reg=lambda_reg))\n",
        "model.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "model.use(mse, mse_prime)\n",
        "model.fit(X_train, y_train, epochs=20, learning_rate=0.1)\n",
        "\n",
        "y_hat = model.predict(X_test)\n",
        "y_hat = [np.argmax(i) for i in y_hat]\n",
        "y_test_labels = [np.argmax(i) for i in y_test]\n",
        "\n",
        "print('Matriz de confusión:')\n",
        "print(confusion_matrix(y_test_labels, y_hat))\n",
        "print(f'Exactitud del modelo: {accuracy_score(y_test_labels, y_hat)}')\n"
      ],
      "metadata": {
        "id": "QaWCCzkLUdh_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}